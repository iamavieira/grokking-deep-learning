{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, weight = [[8.5, .3, 2.3], [.2, 5, 8]];\n",
    "alpha, goal_pred, iteration = (.01, 90, 400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 21.599999999999998 Error: 4678.56\n",
      "Pred: 82.50336 Error: 56.19961128959999\n",
      "Pred: 89.178368256 Error: 0.6750787227484835\n",
      "Pred: 89.9099491608576 Error: 0.008109153630251635\n",
      "Pred: 89.99013042802999 Error: 9.740845087129768e-05\n",
      "Pred: 89.9989182949121 Error: 1.1700858971852834e-06\n",
      "Pred: 89.99988144512236 Error: 1.4055259013369496e-08\n",
      "Pred: 89.99998700638542 Error: 1.688340197342361e-10\n",
      "Pred: 89.99999857589985 Error: 2.0280612316151617e-12\n",
      "Pred: 89.99999984391862 Error: 2.4361398513016338e-14\n",
      "Pred: 89.99999998289348 Error: 2.9263286623568716e-16\n",
      "Pred: 89.99999999812513 Error: 3.515124333899061e-18\n",
      "Pred: 89.99999999979451 Error: 4.2225712345628086e-20\n",
      "Pred: 89.99999999997746 Error: 5.079801767806239e-22\n",
      "Pred: 89.99999999999753 Error: 6.1141895082166665e-24\n",
      "Pred: 89.99999999999973 Error: 7.290336941690503e-26\n",
      "Pred: 89.99999999999997 Error: 8.077935669463161e-28\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28\n",
      "Pred: 90.0 Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "def dot(vec_a, vec_b):\n",
    "    assert(len(vec_a) == len(vec_b));\n",
    "    output = 0;\n",
    "    for i in range(len(vec_a)):\n",
    "        output += vec_a[i] * vec_b[i];\n",
    "    return output;\n",
    "\n",
    "def calc_scalar_vec(scalar, vec):\n",
    "    output = [];\n",
    "    for i in range(len(vec)):\n",
    "        output.append(scalar * vec[i]);\n",
    "    return output;\n",
    "\n",
    "def calc_weight(weight, weight_delta):\n",
    "    output = [];\n",
    "    for i in range(len(weight)):\n",
    "        output.append(weight[i] - weight_delta[i] * alpha);\n",
    "    return output;\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    for i in range(iteration):\n",
    "        pred = dot(input, weight);\n",
    "        msquared_error = (pred - goal_pred) ** 2;\n",
    "        delta = pred - goal_pred;\n",
    "        weight_delta = calc_scalar_vec(delta, input);\n",
    "        weight = calc_weight(weight, weight_delta);\n",
    "        print('Pred: ' + str(pred) + ' Error: ' + str(msquared_error));\n",
    "        if(msquared_error == 0):\n",
    "            break;\n",
    "            \n",
    "neural_network(weight, input);         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 21.599999999999998 Error: 4678.56 Weight: [ 0.2    7.052 23.732] Weight_delta: [   0.    -20.52 -157.32]\n",
      "Pred: 58.39919999999999 Error: 998.6105606400005 Weight: [ 0.2       8.000024 31.000184] Weight_delta: [  0.       -9.48024 -72.68184]\n",
      "Pred: 75.40043039999999 Error: 213.14743250524444 Weight: [ 0.2         8.43801109 34.35808501] Weight_delta: [  0.          -4.37987088 -33.57901008]\n",
      "Pred: 83.2549988448 Error: 45.49504058364934 Weight: [ 0.2         8.64036112 35.90943527] Weight_delta: [  0.          -2.02350035 -15.51350266]\n",
      "Pred: 86.8838094662976 Error: 9.71064344233641 Weight: [ 0.2         8.73384684 36.6261591 ] Weight_delta: [ 0.         -0.93485716 -7.16723823]\n",
      "Pred: 88.5603199734295 Error: 2.0726785789060345 Weight: [ 0.2         8.77703724 36.9572855 ] Weight_delta: [ 0.         -0.43190401 -3.31126406]\n",
      "Pred: 89.33486782772444 Error: 0.4424008065960086 Weight: [ 0.2        8.7969912 37.1102659] Weight_delta: [ 0.         -0.19953965 -1.529804  ]\n",
      "Pred: 89.69270893640869 Error: 0.09442779776307701 Weight: [ 0.2         8.80620994 37.18094285] Weight_delta: [ 0.         -0.09218732 -0.70676945]\n",
      "Pred: 89.85803152862081 Error: 0.020155046865742945 Weight: [ 0.2         8.81046899 37.2135956 ] Weight_delta: [ 0.         -0.04259054 -0.32652748]\n",
      "Pred: 89.93441056622282 Error: 0.0043019738232106825 Weight: [ 0.2         8.81243667 37.22868116] Weight_delta: [ 0.         -0.01967683 -0.1508557 ]\n",
      "Pred: 89.96969768159494 Error: 0.0009182305007218219 Weight: [ 0.2         8.81334574 37.2356507 ] Weight_delta: [ 0.         -0.0090907  -0.06969533]\n",
      "Pred: 89.98600032889686 Error: 0.00019599079099597624 Weight: [ 0.2         8.81376573 37.23887062] Weight_delta: [ 0.         -0.0041999  -0.03219924]\n",
      "Pred: 89.99353215195036 Error: 4.1833058393209854e-05 Weight: [ 0.2         8.81395977 37.24035823] Weight_delta: [ 0.         -0.00194035 -0.01487605]\n",
      "Pred: 89.99701185420106 Error: 8.92901531570831e-06 Weight: [ 0.2         8.81404941 37.2410455 ] Weight_delta: [ 0.         -0.00089644 -0.00687274]\n",
      "Pred: 89.9986194766409 Error: 1.905844745028702e-06 Weight: [ 0.2         8.81409083 37.24136302] Weight_delta: [ 0.         -0.00041416 -0.0031752 ]\n",
      "Pred: 89.99936219820808 Error: 4.067911257822695e-07 Weight: [ 0.2         8.81410996 37.24150972] Weight_delta: [ 0.         -0.00019134 -0.00146694]\n",
      "Pred: 89.99970533557214 Error: 8.682712504322987e-08 Weight: [ 0.2         8.8141188  37.24157749] Weight_delta: [ 0.00000000e+00 -8.83993284e-05 -6.77728184e-04]\n",
      "Pred: 89.99986386503433 Error: 1.8532728878485515e-08 Weight: [ 0.2         8.81412289 37.2416088 ] Weight_delta: [ 0.00000000e+00 -4.08404897e-05 -3.13110421e-04]\n",
      "Pred: 89.99993710564586 Error: 3.955699783229255e-09 Weight: [ 0.2         8.81412477 37.24162327] Weight_delta: [ 0.00000000e+00 -1.88683062e-05 -1.44657015e-04]\n",
      "Pred: 89.99997094280839 Error: 8.44320384321818e-10 Weight: [ 0.2         8.81412565 37.24162995] Weight_delta: [ 0.00000000e+00 -8.71715748e-06 -6.68315407e-05]\n",
      "Pred: 89.99998657557748 Error: 1.8021511997917154e-10 Weight: [ 0.2         8.81412605 37.24163304] Weight_delta: [ 0.00000000e+00 -4.02732676e-06 -3.08761718e-05]\n",
      "Pred: 89.9999937979168 Error: 3.8465836007491003e-11 Weight: [ 0.2         8.81412623 37.24163446] Weight_delta: [ 0.00000000e+00 -1.86062496e-06 -1.42647914e-05]\n",
      "Pred: 89.99999713463757 Error: 8.210301870487788e-12 Weight: [ 0.2         8.81412632 37.24163512] Weight_delta: [ 0.0000000e+00 -8.5960873e-07 -6.5903336e-06]\n",
      "Pred: 89.99999867620255 Error: 1.7524396847852598e-12 Weight: [ 0.2         8.81412636 37.24163543] Weight_delta: [ 0.00000000e+00 -3.97139235e-07 -3.04473413e-06]\n",
      "Pred: 89.99999938840557 Error: 3.7404774706508233e-13 Weight: [ 0.2         8.81412638 37.24163557] Weight_delta: [ 0.00000000e+00 -1.83478329e-07 -1.40666719e-06]\n",
      "Pred: 89.99999971744339 Error: 7.983823942230916e-14 Weight: [ 0.2         8.81412639 37.24163563] Weight_delta: [ 0.00000000e+00 -8.47669838e-08 -6.49880209e-07]\n",
      "Pred: 89.99999986945885 Error: 1.704099262614535e-14 Weight: [ 0.2         8.81412639 37.24163566] Weight_delta: [ 0.00000000e+00 -3.91623459e-08 -3.00244652e-07]\n",
      "Pred: 89.99999993968999 Error: 3.637297880355566e-15 Weight: [ 0.2         8.81412639 37.24163568] Weight_delta: [ 0.00000000e+00 -1.80930044e-08 -1.38713034e-07]\n",
      "Pred: 89.99999997213676 Error: 7.763599789575044e-16 Weight: [ 0.2         8.81412639 37.24163568] Weight_delta: [ 0.00000000e+00 -8.35897112e-09 -6.40854452e-08]\n",
      "Pred: 89.99999998712718 Error: 1.6570942983831368e-16 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -3.86184524e-09 -2.96074802e-08]\n",
      "Pred: 89.99999999405276 Error: 3.536969571262586e-17 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -1.78417281e-09 -1.36786582e-08]\n",
      "Pred: 89.99999999725237 Error: 7.549449331685713e-18 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -8.24287838e-10 -6.31954009e-09]\n",
      "Pred: 89.9999999987306 Error: 1.6113733344884128e-18 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -3.80819642e-10 -2.91961726e-09]\n",
      "Pred: 89.99999999941353 Error: 3.4394443732168925e-19 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -1.75940329e-10 -1.34887586e-09]\n",
      "Pred: 89.99999999972906 Error: 7.341073567057477e-20 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -8.12832468e-11 -6.23171559e-10]\n",
      "Pred: 89.99999999987482 Error: 1.5670888439151484e-20 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -3.75550258e-11 -2.87921864e-10]\n",
      "Pred: 89.99999999994216 Error: 3.345254914277258e-21 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -1.73514536e-11 -1.33027811e-10]\n",
      "Pred: 89.99999999997328 Error: 7.137663957537649e-22 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -8.01492206e-12 -6.14477358e-11]\n",
      "Pred: 89.99999999998765 Error: 1.5250354945218675e-22 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -3.70476982e-12 -2.84032353e-11]\n",
      "Pred: 89.9999999999943 Error: 3.2473503339633643e-23 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -1.70956582e-12 -1.31066713e-11]\n",
      "Pred: 89.99999999999737 Error: 6.911683707184417e-24 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -7.88702437e-13 -6.04671868e-12]\n",
      "Pred: 89.99999999999878 Error: 1.4936103052837384e-24 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -3.66640052e-13 -2.81090706e-12]\n",
      "Pred: 89.99999999999945 Error: 3.071635038313367e-25 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -1.66267000e-13 -1.27471367e-12]\n",
      "Pred: 89.99999999999974 Error: 6.54312789226516e-26 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -7.67386155e-14 -5.88329385e-13]\n",
      "Pred: 89.99999999999987 Error: 1.63578197306629e-26 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -3.83693077e-14 -2.94164693e-13]\n",
      "Pred: 89.99999999999994 Error: 3.2311742677852644e-27 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -1.70530257e-14 -1.30739863e-13]\n",
      "Pred: 89.99999999999997 Error: 8.077935669463161e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -8.52651283e-15 -6.53699317e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n",
      "Pred: 89.99999999999999 Error: 2.0194839173657902e-28 Weight: [ 0.2         8.81412639 37.24163569] Weight_delta: [ 0.00000000e+00 -4.26325641e-15 -3.26849658e-14]\n"
     ]
    }
   ],
   "source": [
    "alpha = .1;\n",
    "def neural_network(input, weight):\n",
    "    for i in range(iteration):\n",
    "        pred = np.dot(input, weight);\n",
    "        msquared_error = (pred - goal_pred) ** 2\n",
    "        delta = pred - goal_pred;\n",
    "        weight_delta = np.dot(delta, input);\n",
    "        weight_delta[0] = 0;\n",
    "        weight = np.subtract(weight, np.dot(weight_delta, alpha))\n",
    "        print('Pred: ' + str(pred) + ' Error: ' + str(msquared_error) \\\n",
    "              + ' Weight: ' + str(weight) + ' Weight_delta: ' + str(weight_delta))\n",
    "              #+ ' Delta: ' + str(delta));\n",
    "        if( msquared_error == 0):\n",
    "            break;\n",
    "        \n",
    "neural_network(input, weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha was set lower given the high value of input a, \n",
    "that was causing the network to overshoot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent with multiple outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [1.7000000000000002, 42.5, 68.0] \n",
      "Error: [334.89000000000004, 209306.25, 4356.0]\n",
      "Pred: [14.921750000000001, 373.04375000000005, 20.314999999999998] \n",
      "Error: [25.788623062499987, 16117.889414062489, 335.4392249999999]\n",
      "Pred: [18.590785625, 464.769640625, 7.082412499999999] \n",
      "Error: [1.985885154706644, 1241.1782216916488, 25.830916820156244]\n",
      "Pred: [19.6089430109375, 490.2235752734375, 3.410369468749999] \n",
      "Error: [0.152925568694627, 95.57848043414229, 1.9891420383821545]\n",
      "Pred: [19.891481685535155, 497.2870421383789, 2.3913775275781246] \n",
      "Error: [0.011776224574291071, 7.360140358931612, 0.15317636909316568]\n",
      "Pred: [19.969886167736007, 499.2471541934001, 2.10860726390293] \n",
      "Error: [0.0009068428936238992, 0.5667768085150654, 0.011795537772480649]\n",
      "Pred: [19.991643411546743, 499.79108528866857, 2.030138515733063] \n",
      "Error: [6.98325705771052e-05, 0.0436453566106952, 0.0009083301305920811]\n",
      "Pred: [19.99768104670422, 499.9420261676055, 2.008363438115925] \n",
      "Error: [5.3775443880126405e-06, 0.0033609652425066645, 6.994709711890699e-05]\n",
      "Pred: [19.99935649046042, 499.98391226151057, 2.002320854077169] \n",
      "Error: [4.1410452752879255e-07, 0.0002588153297043522, 5.386363647512378e-06]\n",
      "Pred: [19.999821426102766, 499.9955356525692, 2.0006440370064147] \n",
      "Error: [3.188863677324882e-08, 1.9930397983121906e-05, 4.1478366563159326e-07]\n",
      "Pred: [19.99995044574352, 499.99876114358796, 2.00017872026928] \n",
      "Error: [2.4556243354187617e-09, 1.5347652096631338e-06, 3.19409346514393e-08]\n",
      "Pred: [19.999986248693826, 499.99965621734566, 2.0000495948747252] \n",
      "Error: [1.8909842148447073e-10, 1.1818651342535148e-07, 2.4596515990105468e-09]\n",
      "Pred: [19.999996184012538, 499.9999046003134, 2.000013762577736] \n",
      "Error: [1.4561760310287475e-11, 9.101100200708227e-09, 1.894085459424555e-10]\n",
      "Pred: [19.99999894106348, 499.999973526587, 2.0000038191153218] \n",
      "Error: [1.1213465510943556e-12, 7.008415966912313e-10, 1.4585641840964252e-11]\n",
      "Pred: [19.99999970614512, 499.99999265362794, 2.000001059804502] \n",
      "Error: [8.635069153479207e-14, 5.3969182418041496e-11, 1.1231855823216745e-12]\n",
      "Pred: [19.999999918455266, 499.9999979613817, 2.000000294095749] \n",
      "Error: [6.6495435831463675e-15, 4.155964478731902e-12, 8.649230963111418e-14]\n",
      "Pred: [19.999999977371335, 499.99999943428344, 2.0000000816115704] \n",
      "Error: [5.120564870995822e-16, 3.200352280637336e-13, 6.660448421611625e-15]\n",
      "Pred: [19.999999993720547, 499.99999984301365, 2.0000000226472108] \n",
      "Error: [3.943153502415931e-17, 2.4644712736464682e-14, 5.128961558141481e-16]\n",
      "Pred: [19.99999999825745, 499.9999999564362, 2.000000006284601] \n",
      "Error: [3.0364777702964733e-18, 1.8978023209041748e-15, 3.9496207714789907e-17]\n",
      "Pred: [19.999999999516444, 499.9999999879111, 2.000000001743977] \n",
      "Error: [2.3382670117667587e-19, 1.4614125875146217e-16, 3.041455646925186e-18]\n",
      "Pred: [19.99999999986581, 499.99999999664533, 2.0000000004839533] \n",
      "Error: [1.8006834889590484e-20, 1.1253818910358696e-17, 2.3421081774074513e-19]\n",
      "Pred: [19.999999999962764, 499.9999999990691, 2.000000000134297] \n",
      "Error: [1.3865191052515224e-21, 8.666207424870952e-19, 1.8035689030466065e-20]\n",
      "Pred: [19.999999999989665, 499.99999999974165, 2.0000000000372675] \n",
      "Error: [1.068090023983131e-22, 6.67464476289969e-20, 1.3888682259394027e-21]\n",
      "Pred: [19.999999999997133, 499.9999999999283, 2.0000000000103415] \n",
      "Error: [8.21991801062846e-24, 5.137958057864972e-21, 1.069467345541363e-22]\n",
      "Pred: [19.999999999999204, 499.9999999999801, 2.00000000000287] \n",
      "Error: [6.333101564859118e-25, 3.958188478036949e-22, 8.237752775188922e-24]\n",
      "Pred: [19.99999999999978, 499.9999999999945, 2.0000000000007963] \n",
      "Error: [4.851810111471311e-26, 3.040211868559155e-23, 6.340171730722161e-25]\n",
      "Pred: [19.999999999999936, 499.99999999999847, 2.000000000000221] \n",
      "Error: [4.089454932665725e-27, 2.3555260412154577e-24, 4.8910164984607953e-26]\n",
      "Pred: [19.999999999999982, 499.99999999999955, 2.0000000000000613] \n",
      "Error: [3.155443620884047e-28, 2.0679515313825692e-25, 3.755766769757237e-27]\n",
      "Pred: [19.999999999999993, 499.99999999999983, 2.000000000000017] \n",
      "Error: [5.048709793414476e-29, 2.908056841006738e-26, 2.8477878678478526e-28]\n",
      "Pred: [19.999999999999996, 500.0, 2.000000000000005] \n",
      "Error: [1.262177448353619e-29, 0.0, 2.3863042382935607e-29]\n",
      "Pred: [20.0, 500.0, 2.0000000000000013] \n",
      "Error: [0.0, 0.0, 1.7749370367472766e-30]\n",
      "Pred: [20.0, 500.0, 2.0] \n",
      "Error: [0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "input, alpha = 8.5, .01;\n",
    "weight, goal_pred = [[.2, 5, 8], [20, 500, 2]];\n",
    "def msquared(pred, goal_pred):\n",
    "    assert(len(pred) == len(goal_pred));\n",
    "    error = [];\n",
    "    for i in range(len(goal_pred)):\n",
    "        error.append((pred[i] - goal_pred[i]) ** 2);\n",
    "    return error;\n",
    "\n",
    "def calc_delta(pred, goal_pred):\n",
    "    output = [];\n",
    "    for i in range(len(goal_pred)):\n",
    "        output.append(pred[i] - goal_pred[i]);\n",
    "    return output;\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    for i in range(iteration):\n",
    "        pred = calc_scalar_vec(input, weight);\n",
    "        msquared_error = msquared(pred, goal_pred);\n",
    "        delta = calc_delta(pred, goal_pred);\n",
    "        weight_delta = calc_scalar_vec(input, delta);\n",
    "        weight = calc_weight(weight, weight_delta);\n",
    "        print('Pred: ' + str(pred) + ' \\nError: ' + str(msquared_error));\n",
    "        if (not np.any(msquared_error)): break;\n",
    "        \n",
    "neural_network(input, weight);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [ 1.7 42.5 68. ] Error: [   334.89 209306.25   4356.  ]\n",
      "Delta: [ -18.3 -457.5   66. ] Weight_delta: [ -155.55 -3888.75   561.  ]\n",
      "Pred: [ 14.92175 373.04375  20.315  ] Error: [   25.78862306 16117.88941406   335.439225  ]\n",
      "Delta: [  -5.07825 -126.95625   18.315  ] Weight_delta: [  -43.165125 -1079.128125   155.6775  ]\n",
      "Pred: [ 18.59078562 464.76964063   7.0824125 ] Error: [   1.98588515 1241.17822169   25.83091682]\n",
      "Delta: [ -1.40921438 -35.23035937   5.0824125 ] Weight_delta: [ -11.97832219 -299.45805469   43.20050625]\n",
      "Pred: [ 19.60894301 490.22357527   3.41036947] Error: [ 0.15292557 95.57848043  1.98914204]\n",
      "Delta: [-0.39105699 -9.77642473  1.41036947] Weight_delta: [ -3.32398441 -83.09961018  11.98814048]\n",
      "Pred: [ 19.89148169 497.28704214   2.39137753] Error: [0.01177622 7.36014036 0.15317637]\n",
      "Delta: [-0.10851831 -2.71295786  0.39137753] Weight_delta: [ -0.92240567 -23.06014182   3.32670898]\n",
      "Pred: [ 19.96988617 499.24715419   2.10860726] Error: [0.00090684 0.56677681 0.01179554]\n",
      "Delta: [-0.03011383 -0.75284581  0.10860726] Weight_delta: [-0.25596757 -6.39918936  0.92316174]\n",
      "Pred: [ 19.99164341 499.79108529   2.03013852] Error: [6.98325706e-05 4.36453566e-02 9.08330131e-04]\n",
      "Delta: [-0.00835659 -0.20891471  0.03013852] Weight_delta: [-0.071031   -1.77577505  0.25617738]\n",
      "Pred: [ 19.99768105 499.94202617   2.00836344] Error: [5.37754439e-06 3.36096524e-03 6.99470971e-05]\n",
      "Delta: [-0.00231895 -0.05797383  0.00836344] Weight_delta: [-0.0197111  -0.49277758  0.07108922]\n",
      "Pred: [ 19.99935649 499.98391226   2.00232085] Error: [4.14104528e-07 2.58815330e-04 5.38636365e-06]\n",
      "Delta: [-0.00064351 -0.01608774  0.00232085] Weight_delta: [-0.00546983 -0.13674578  0.01972726]\n",
      "Pred: [ 19.99982143 499.99553565   2.00064404] Error: [3.18886368e-08 1.99303980e-05 4.14783666e-07]\n",
      "Delta: [-0.00017857 -0.00446435  0.00064404] Weight_delta: [-0.00151788 -0.03794695  0.00547431]\n",
      "Pred: [ 19.99995045 499.99876114   2.00017872] Error: [2.45562434e-09 1.53476521e-06 3.19409347e-08]\n",
      "Delta: [-4.95542565e-05 -1.23885641e-03  1.78720269e-04] Weight_delta: [-0.00042121 -0.01053028  0.00151912]\n",
      "Pred: [ 19.99998625 499.99965622   2.00004959] Error: [1.89098421e-10 1.18186513e-07 2.45965160e-09]\n",
      "Delta: [-1.37513062e-05 -3.43782654e-04  4.95948747e-05] Weight_delta: [-0.00011689 -0.00292215  0.00042156]\n",
      "Pred: [ 19.99999618 499.9999046    2.00001376] Error: [1.45617603e-11 9.10110020e-09 1.89408546e-10]\n",
      "Delta: [-3.81598746e-06 -9.53996866e-05  1.37625777e-05] Weight_delta: [-3.24358934e-05 -8.10897336e-04  1.16981911e-04]\n",
      "Pred: [ 19.99999894 499.99997353   2.00000382] Error: [1.12134655e-12 7.00841597e-10 1.45856418e-11]\n",
      "Delta: [-1.05893652e-06 -2.64734130e-05  3.81911532e-06] Weight_delta: [-9.00096041e-06 -2.25024011e-04  3.24624802e-05]\n",
      "Pred: [ 19.99999971 499.99999265   2.00000106] Error: [8.63506915e-14 5.39691824e-11 1.12318558e-12]\n",
      "Delta: [-2.93854882e-07 -7.34637206e-06  1.05980450e-06] Weight_delta: [-2.49776649e-06 -6.24441625e-05  9.00833827e-06]\n",
      "Pred: [ 19.99999992 499.99999796   2.00000029] Error: [6.64954358e-15 4.15596448e-12 8.64923096e-14]\n",
      "Delta: [-8.15447336e-08 -2.03861828e-06  2.94095749e-07] Weight_delta: [-6.93130236e-07 -1.73282554e-05  2.49981387e-06]\n",
      "Pred: [ 19.99999998 499.99999943   2.00000008] Error: [5.12056487e-16 3.20035228e-13 6.66044842e-15]\n",
      "Delta: [-2.26286652e-08 -5.65716562e-07  8.16115704e-08] Weight_delta: [-1.92343654e-07 -4.80859077e-06  6.93698348e-07]\n",
      "Pred: [ 19.99999999 499.99999984   2.00000002] Error: [3.94315350e-17 2.46447127e-14 5.12896156e-16]\n",
      "Delta: [-6.27945340e-09 -1.56986346e-07  2.26472108e-08] Weight_delta: [-5.33753539e-08 -1.33438394e-06  1.92501292e-07]\n",
      "Pred: [ 20.         499.99999996   2.00000001] Error: [3.03647777e-18 1.89780232e-15 3.94962077e-17]\n",
      "Delta: [-1.74254922e-09 -4.35637730e-08  6.28460084e-09] Weight_delta: [-1.48116683e-08 -3.70292071e-07  5.34191071e-08]\n",
      "Pred: [ 20.         499.99999999   2.        ] Error: [2.33826701e-19 1.46141259e-16 3.04145565e-18]\n",
      "Delta: [-4.83556306e-10 -1.20888899e-08  1.74397696e-09] Weight_delta: [-4.11022860e-09 -1.02755564e-07  1.48238042e-08]\n",
      "Pred: [ 20. 500.   2.] Error: [1.80068349e-20 1.12538189e-17 2.34210818e-19]\n",
      "Delta: [-1.34189548e-10 -3.35467121e-09  4.83953322e-10] Weight_delta: [-1.14061116e-09 -2.85147053e-08  4.11360324e-09]\n",
      "Pred: [ 20. 500.   2.] Error: [1.38651911e-21 8.66620742e-19 1.80356890e-20]\n",
      "Delta: [-3.72359921e-11 -9.30924671e-10  1.34297018e-10] Weight_delta: [-3.16505933e-10 -7.91285970e-09  1.14152465e-09]\n",
      "Pred: [ 20. 500.   2.] Error: [1.06809002e-22 6.67464476e-20 1.38886823e-21]\n",
      "Delta: [-1.03348441e-11 -2.58353339e-10  3.72675224e-11] Weight_delta: [-8.78461748e-11 -2.19600338e-09  3.16773940e-10]\n",
      "Pred: [ 20. 500.   2.] Error: [8.21991801e-24 5.13795806e-21 1.06946735e-22]\n",
      "Delta: [-2.86703994e-12 -7.16795512e-11  1.03415054e-11] Weight_delta: [-2.43698395e-11 -6.09276185e-10  8.79027962e-11]\n",
      "Pred: [ 20. 500.   2.] Error: [6.33310156e-25 3.95818848e-22 8.23775278e-24]\n",
      "Delta: [-7.95807864e-13 -1.98951966e-11  2.87014856e-12] Weight_delta: [-6.76436684e-12 -1.69109171e-10  2.43962628e-11]\n",
      "Pred: [ 20. 500.   2.] Error: [4.85181011e-26 3.04021187e-23 6.34017173e-25]\n",
      "Delta: [-2.20268248e-13 -5.51381163e-12  7.96251953e-13] Weight_delta: [-1.87228011e-12 -4.68673989e-11  6.76814160e-12]\n",
      "Pred: [ 20. 500.   2.] Error: [4.08945493e-27 2.35552604e-24 4.89101650e-26]\n",
      "Delta: [-6.39488462e-14 -1.53477231e-12  2.21156427e-13] Weight_delta: [-5.43565193e-13 -1.30455646e-11  1.87982963e-12]\n",
      "Pred: [ 20. 500.   2.] Error: [3.15544362e-28 2.06795153e-25 3.75576677e-27]\n",
      "Delta: [-1.77635684e-14 -4.54747351e-13  6.12843110e-14] Weight_delta: [-1.50990331e-13 -3.86535248e-12  5.20916643e-13]\n",
      "Pred: [ 20. 500.   2.] Error: [5.04870979e-29 2.90805684e-26 2.84778787e-28]\n",
      "Delta: [-7.10542736e-15 -1.70530257e-13  1.68753900e-14] Weight_delta: [-6.03961325e-14 -1.44950718e-12  1.43440815e-13]\n",
      "Pred: [ 20. 500.   2.] Error: [1.26217745e-29 0.00000000e+00 2.38630424e-29]\n",
      "Delta: [-3.55271368e-15  0.00000000e+00  4.88498131e-15] Weight_delta: [-3.01980663e-14  0.00000000e+00  4.15223411e-14]\n",
      "Pred: [ 20. 500.   2.] Error: [0.00000000e+00 0.00000000e+00 1.77493704e-30]\n",
      "Delta: [0.00000000e+00 0.00000000e+00 1.33226763e-15] Weight_delta: [0.00000000e+00 0.00000000e+00 1.13242749e-14]\n",
      "Pred: [ 20. 500.   2.] Error: [0. 0. 0.]\n",
      "Delta: [0. 0. 0.] Weight_delta: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "input, alpha = 8.5, .01;\n",
    "weight, goal_pred = np.array([.2, 5, 8]), np.array([20, 500, 2]);\n",
    "def neural_network(input, weight):\n",
    "    for i in range(iteration):\n",
    "        pred = np.dot(input, weight);\n",
    "        msquared_error = (np.subtract(pred, goal_pred)) ** 2\n",
    "        delta = np.subtract(pred, goal_pred);\n",
    "        weight_delta = np.dot(input, delta);\n",
    "        weight = np.subtract(weight, np.dot(weight_delta, alpha));\n",
    "        print('Pred: ' + str(pred) + ' Error: ' + str(msquared_error));\n",
    "        print('Delta: ' + str(delta) + ' Weight_delta: ' + str(weight_delta));\n",
    "        if(not np.any(msquared_error)): break;\n",
    "            \n",
    "neural_network(input, weight);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent with multiple inputs, multiples outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [0, 0, 0] Error: [0.04000000000000001, 0.09, 0.36]\n",
      "---------------\n",
      "Pred: [0.1653, 0.24795000000000003, 0.49590000000000006] Error: [0.0012040900000000005, 0.0027092024999999954, 0.010836809999999981]\n",
      "---------------\n",
      "Pred: [0.19397955000000003, 0.290969325, 0.58193865] Error: [3.6245818202499794e-05, 8.155309095562478e-05, 0.00032621236382249913]\n",
      "---------------\n",
      "Pred: [0.198955451925, 0.29843317788749996, 0.5968663557749999] Error: [1.0910806809862316e-06, 2.4549315322190648e-06, 9.819726128876259e-06]\n",
      "---------------\n",
      "Pred: [0.19981877090898753, 0.2997281563634812, 0.5994563127269624] Error: [3.284398342920987e-08, 7.389896271575238e-08, 2.9559585086300953e-07]\n",
      "---------------\n",
      "Pred: [0.1999685567527093, 0.299952835129064, 0.599905670258128] Error: [9.886778001846034e-10, 2.224525050407503e-09, 8.898100201630013e-09]\n",
      "---------------\n",
      "Pred: [0.19999454459659508, 0.29999181689489257, 0.5999836337897851] Error: [2.976142631058608e-11, 6.696320919904581e-11, 2.6785283679618323e-10]\n",
      "---------------\n",
      "Pred: [0.1999990534875093, 0.2999985802312639, 0.5999971604625278] Error: [8.958858950855683e-13, 2.0157432639425286e-12, 8.062973055770114e-12]\n",
      "---------------\n",
      "Pred: [0.1999998357800829, 0.29999975367012427, 0.5999995073402485] Error: [2.6968181175366604e-14, 6.067840767192297e-14, 2.427136306876919e-13]\n",
      "---------------\n",
      "Pred: [0.19999997150784438, 0.29999995726176654, 0.5999999145235331] Error: [8.118029327193424e-16, 1.8265565986185204e-15, 7.306226394474082e-15]\n",
      "---------------\n",
      "Pred: [0.199999995056611, 0.2999999925849165, 0.599999985169833] Error: [2.4437094841878528e-17, 5.4983463188416775e-17, 2.199338527536671e-16]\n",
      "---------------\n",
      "Pred: [0.199999999142322, 0.29999999871348304, 0.5999999974269661] Error: [7.356115721741676e-19, 1.65512585885178e-18, 6.62050343540712e-18]\n",
      "---------------\n",
      "Pred: [0.1999999998511929, 0.2999999997767893, 0.5999999995535786] Error: [2.2143554655225958e-20, 4.98230041695989e-20, 1.992920166783956e-19]\n",
      "---------------\n",
      "Pred: [0.19999999997418197, 0.2999999999612729, 0.5999999999225458] Error: [6.665713003883684e-22, 1.499786500765953e-21, 5.999146003063812e-21]\n",
      "---------------\n",
      "Pred: [0.1999999999955206, 0.29999999999328086, 0.5999999999865617] Error: [2.006517520367642e-23, 4.5146644208271947e-23, 1.8058657683308779e-22]\n",
      "---------------\n",
      "Pred: [0.19999999999922283, 0.29999999999883425, 0.5999999999976685] Error: [6.040147721609634e-25, 1.3589361687596336e-24, 5.4357446750385345e-24]\n",
      "---------------\n",
      "Pred: [0.19999999999986517, 0.2999999999997977, 0.5999999999995954] Error: [1.8180905016019858e-26, 4.091826445762046e-26, 1.6367305783048183e-25]\n",
      "---------------\n",
      "Pred: [0.19999999999997664, 0.29999999999996496, 0.5999999999999299] Error: [5.461659988370209e-28, 1.226928308139466e-27, 4.907713232557864e-27]\n",
      "---------------\n",
      "Pred: [0.19999999999999596, 0.2999999999999939, 0.5999999999999878] Error: [1.6421249077823328e-29, 3.7286003723336886e-29, 1.4914401489334754e-28]\n",
      "---------------\n",
      "Pred: [0.1999999999999993, 0.29999999999999893, 0.5999999999999979] Error: [5.207714569623086e-31, 1.1124171358780674e-30, 4.44966854351227e-30]\n",
      "---------------\n",
      "Pred: [0.19999999999999987, 0.2999999999999998, 0.5999999999999996] Error: [1.9259299443872359e-32, 2.7733391199176196e-32, 1.1093356479670479e-31]\n",
      "---------------\n",
      "Pred: [0.2, 0.3, 0.6] Error: [0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "input, goal_pred = [ [85, 32, 4], [.2, .3, .6] ];\n",
    "weights = [ [0, 0, 0],\n",
    "           [0, 0, 0],\n",
    "           [0, 0, 0] ];\n",
    "alpha = .0001;\n",
    "\n",
    "def vec_matrix_mult(vec, matrix):\n",
    "    output = [];\n",
    "    for i in range(len(matrix)):\n",
    "        assert(len(vec) == len(matrix[i]));\n",
    "        output.append(dot(vec, matrix[i]));\n",
    "    return output;\n",
    "\n",
    "def calc_weight_delta(input, delta):\n",
    "    assert(len(input) == len(delta));\n",
    "    output = []; \n",
    "    for i in range(len(delta)): \n",
    "        output.append(calc_scalar_vec(delta[i], input));\n",
    "    return output;\n",
    "\n",
    "def wrap(weights, weight_delta):\n",
    "    assert(len(weights) == len(weight_delta))\n",
    "    output = []\n",
    "    for i in range(len(weight)):\n",
    "        output.append(calc_weight(weights[i], weight_delta[i]));\n",
    "    return output;\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    for i in range(iteration):\n",
    "        pred = vec_matrix_mult(input, weights);\n",
    "        msquared_error = msquared(pred, goal_pred);\n",
    "        delta = calc_delta(pred, goal_pred);\n",
    "        weight_delta = calc_weight_delta(input, delta);\n",
    "        weights = wrap(weights, weight_delta);\n",
    "        print('Pred: ' + str(pred) + ' Error: ' + str(msquared_error));\n",
    "        if(not np.any(msquared_error)): break;\n",
    "        print('---------------');\n",
    "        \n",
    "neural_network(input, weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [15.19166264 11.86599625  9.58752774  5.8916517 ] Error: [5.17200115e+01 1.66573365e+05 9.02476535e+04 9.88251408e+05]\n",
      "Pred: [ 13.57353855 103.69614709  77.180334   229.56603007] Error: [3.10643319e+01 1.00048127e+05 5.42049969e+04 5.93568502e+05]\n",
      "Pred: [ 12.31949237 174.864514   129.56475885 402.9136733 ] Error: [1.86580144e+01 6.00914065e+04 3.25568763e+04 3.56512082e+05]\n",
      "Pred: [ 11.34760659 230.01999835 170.16268811 537.25809681] Error: [1.12064699e+01 3.60924010e+04 1.95544738e+04 2.14130069e+05]\n",
      "Pred: [ 10.59439511 272.76549872 201.62608328 641.37502503] Error: [6.73088597e+00 2.16779984e+04 1.17449058e+04 1.28611873e+05]\n",
      "Pred: [ 10.01065621 305.89326151 226.01021454 722.0656444 ] Error: [4.04273839e+00 1.30203478e+04 7.05428406e+03 7.72475060e+04]\n",
      "Pred: [  9.55825856 331.56727767 244.90791627 784.60087441] Error: [2.42816974e+00 7.82034638e+03 4.23697936e+03 4.63967833e+04]\n",
      "Pred: [  9.20765038 351.46464019 259.55363511 833.06567767] Error: [1.45841945e+00 4.69709554e+03 2.54483573e+03 2.78670680e+04]\n",
      "Pred: [  8.93592905 366.88509615 270.90406721 870.62590019] Error: [8.75963183e-01 2.82119301e+03 1.52849196e+03 1.67376577e+04]\n",
      "Pred: [  8.72534501 378.83594952 279.70065209 899.73507265] Error: [5.26125387e-01 1.69447905e+03 9.18050484e+02 1.00530557e+04]\n",
      "Pred: [  8.56214238 388.09786087 286.51800537 922.2946813 ] Error: [3.16004061e-01 1.01774648e+03 5.51404072e+02 6.03811655e+03]\n",
      "Pred: [  8.43566035 395.27584218 291.80145416 939.77837801] Error: [1.89799939e-01 6.11283980e+02 3.31187071e+02 3.62664376e+03]\n",
      "Pred: [  8.33763677 400.83877769 295.89612697 953.32824296] Error: [1.13998588e-01 3.67152440e+02 1.98919234e+02 2.17825291e+03]\n",
      "Pred: [  8.2616685  405.15005271 299.06949841 963.82938829] Error: [6.84704021e-02 2.20520935e+02 1.19475865e+02 1.30831315e+03]\n",
      "Pred: [  8.20279308 408.49129085 301.52886126 971.96777593] Error: [4.11250353e-02 1.32450386e+02 7.17601915e+01 7.85805587e+02]\n",
      "Pred: [  8.15716464 411.08075041 303.43486748 978.27502634] Error: [2.47007243e-02 7.95530133e+01 4.31009650e+01 4.71974480e+02]\n",
      "Pred: [  8.1218026  413.08758157 304.9120223  983.16314542] Error: [1.48358725e-02 4.77815286e+01 2.58875171e+01 2.83479672e+02]\n",
      "Pred: [  8.09439701 414.64287571 306.05681728 986.9514377 ] Error: [8.91079594e-03 2.86987806e+01 1.55486900e+01 1.70264978e+02]\n",
      "Pred: [  8.07315768 415.84822868 306.94403339 989.88736422] Error: [5.35204681e-03 1.72372051e+01 9.33893191e+00 1.02265403e+02]\n",
      "Pred: [  8.05669721 416.78237723 307.63162588 992.16270727] Error: [3.21457312e-03 1.03530963e+01 5.60919598e+00 6.14231574e+01]\n",
      "Pred: [  8.04394033 417.50634235 308.16451006 993.92609813] Error: [1.93075298e-03 6.21832848e+00 3.36902333e+00 3.68922839e+01]\n",
      "Pred: [  8.03405376 418.06741532 308.57749529 995.29272605] Error: [1.15965851e-03 3.73488354e+00 2.02351964e+00 2.21584280e+01]\n",
      "Pred: [  8.02639166 418.50224687 308.89755885 996.35186269] Error: [6.96519891e-04 2.24326443e+00 1.21537648e+00 1.33089058e+01]\n",
      "Pred: [  8.02045354 418.83924133 309.14560811 997.17269359] Error: [4.18347260e-04 1.34736070e+00 7.29985501e-01 7.99366156e+00]\n",
      "Pred: [  8.01585149 419.10041203 309.33784629 997.80883753] Error: [2.51269823e-04 8.09258518e-01 4.38447541e-01 4.80119298e+00]\n",
      "Pred: [  8.01228491 419.30281932 309.48683087 998.30184908] Error: [1.50918937e-04 4.86060898e-01 2.63342555e-01 2.88371653e+00]\n",
      "Pred: [  8.0095208  419.45968497 309.60229393 998.68393304] Error: [9.06456867e-05 2.91940327e-01 1.58170122e-01 1.73203224e+00]\n",
      "Pred: [  8.00737862 419.58125586 309.69177779 998.98004811] Error: [5.44440656e-05 1.75346659e-01 9.50009294e-02 1.04030187e+00]\n",
      "Pred: [  8.00571843 419.67547329 309.76112779 999.20953728] Error: [3.27004669e-05 1.05317587e-01 5.70599332e-02 6.24831308e-01]\n",
      "Pred: [  8.00443178 419.7484918  309.81487404 999.38739139] Error: [1.96407179e-05 6.32563756e-02 3.42716224e-02 3.75289304e-01]\n",
      "Pred: [  8.00343463 419.80508114 309.85652738 999.52522833] Error: [1.17967062e-05 3.79933606e-02 2.05843932e-02 2.25408138e-01]\n",
      "Pred: [  8.00266184 419.84893789 309.88880872 999.63205196] Error: [7.08539666e-06 2.28197622e-02 1.23635012e-02 1.35385763e-01]\n",
      "Pred: [  8.00206293 419.88292686 309.91382676 999.71484027] Error: [4.25566637e-06 1.37061197e-02 7.42582789e-03 8.13160740e-02]\n",
      "Pred: [  8.00159877 419.90926832 309.93321574 999.77900121] Error: [2.55605961e-06 8.23223813e-03 4.46013788e-03 4.88404669e-02]\n",
      "Pred: [  8.00123905 419.92968295 309.9482422  999.82872593] Error: [1.53523331e-06 4.94448803e-03 2.67887031e-03 2.93348054e-02]\n",
      "Pred: [  8.00096026 419.94550428 309.9598877  999.8672626 ] Error: [9.22099504e-07 2.96978312e-03 1.60899648e-03 1.76192175e-02]\n",
      "Pred: [  8.0007442  419.95776582 309.96891297 999.89712851] Error: [5.53836015e-07 1.78372599e-03 9.66403511e-04 1.05825425e-02]\n",
      "Pred: [  8.00057676 419.96726851 309.97590755 999.9202746 ] Error: [3.32647756e-07 1.07135042e-03 5.80446109e-04 6.35613960e-03]\n",
      "Pred: [  8.00044699 419.9746331  309.98132835 999.93821281] Error: [1.99796559e-07 6.43479847e-04 3.48630444e-04 3.81765635e-03]\n",
      "Pred: [  8.00034641 419.98034065 309.98552947 999.95211493] Error: [1.20002808e-07 3.86490083e-04 2.09396161e-04 2.29297984e-03]\n",
      "Pred: [  8.00026847 419.984764   309.98878534 999.96288907] Error: [7.20766866e-08 2.32135606e-04 1.25768569e-04 1.37722102e-03]\n",
      "Pred: [  8.00020807 419.9881921  309.99130864 999.97123903] Error: [4.32910599e-08 1.39426448e-04 7.55397467e-05 8.27193375e-04]\n",
      "Pred: [  8.00016125 419.99084888 309.9932642  999.97771025] Error: [2.60016928e-08 8.37430106e-05 4.53710604e-05 4.96833021e-04]\n",
      "Pred: [  8.00012497 419.99290788 309.99477975 999.98272544] Error: [1.56172668e-08 5.02981457e-05 2.72509931e-05 2.98410333e-04]\n",
      "Pred: [  8.00009685 419.99450361 309.99595431 999.98661222] Error: [9.38012085e-09 3.02103238e-05 1.63676278e-05 1.79232706e-04]\n",
      "Pred: [  8.00007506 419.9957403  309.99686459 999.98962447] Error: [5.63393509e-09 1.81450757e-05 9.83080642e-06 1.07651644e-04]\n",
      "Pred: [  8.00005817 419.99669873 309.99757006 999.99195896] Error: [3.38388226e-09 1.08983861e-05 5.90462810e-06 6.46582688e-05]\n",
      "Pred: [  8.00004508 419.99744152 309.99811679 999.9937682 ] Error: [2.03244428e-09 6.54584315e-06 3.54646726e-06 3.88353727e-05]\n",
      "Pred: [  8.00003494 419.99801717 309.99854051 999.99517035] Error: [1.22073685e-09 3.93159704e-06 2.13009690e-06 2.33254957e-05]\n",
      "Pred: [  8.00002708 419.99846331 309.9988689  999.99625702] Error: [7.33205069e-10 2.36141547e-06 1.27938945e-06 1.40098759e-05]\n",
      "Pred: [  8.00002099 419.99880907 309.9991234  999.99709919] Error: [4.40381295e-10 1.41832517e-06 7.68433287e-07 8.41468170e-06]\n",
      "Pred: [  8.00001626 419.99907703 309.99932063 999.99775187] Error: [2.64504015e-10 8.51881555e-07 4.61540243e-07 5.05406819e-06]\n",
      "Pred: [  8.0000126  419.99928469 309.99947349 999.9982577 ] Error: [1.58867724e-10 5.11661359e-07 2.77212608e-07 3.03559971e-06]\n",
      "Pred: [  8.00000977 419.99944564 309.99959195 999.99864972] Error: [9.54199267e-11 3.07316604e-07 1.66500823e-07 1.82325707e-06]\n",
      "Pred: [  8.00000757 419.99957037 309.99968377 999.99895353] Error: [5.73115935e-11 1.84582035e-07 1.00004557e-07 1.09509378e-06]\n",
      "Pred: [  8.00000587 419.99966704 309.99975492 999.99918899] Error: [3.44227759e-11 1.10864585e-07 6.00652369e-08 6.57740702e-07]\n",
      "Pred: [  8.00000455 419.99974195 309.99981006 999.99937147] Error: [2.06751797e-11 6.65880412e-08 3.60766829e-08 3.95055509e-07]\n",
      "Pred: [  8.00000352 419.99980001 309.9998528  999.99951289] Error: [1.24180298e-11 3.99944423e-08 2.16685577e-08 2.37280215e-07]\n",
      "Pred: [  8.00000273 419.99984501 309.99988592 999.99962249] Error: [7.45857916e-12 2.40216619e-08 1.30146775e-08 1.42516429e-07]\n",
      "Pred: [  8.00000212 419.99987988 309.99991159 999.99970743] Error: [4.47980911e-12 1.44280107e-08 7.81694064e-09 8.55989304e-08]\n",
      "Pred: [  8.00000164 419.99990691 309.99993148 999.99977326] Error: [2.69068535e-12 8.66582391e-09 4.69504998e-09 5.14128576e-08]\n",
      "Pred: [  8.00000127 419.99992785 309.9999469  999.99982427] Error: [1.61609289e-12 5.20491049e-09 2.81996439e-09 3.08798476e-08]\n",
      "Pred: [  8.00000099 419.99994409 309.99995884 999.99986381] Error: [9.70665788e-13 3.12619936e-09 1.69374111e-09 1.85472084e-08]\n",
      "Pred: [  8.00000076 419.99995667 309.9999681  999.99989445] Error: [5.83006140e-13 1.87767349e-09 1.01730325e-09 1.11399171e-08]\n",
      "Pred: [  8.00000059 419.99996642 309.99997528 999.9999182 ] Error: [3.50168063e-13 1.12777764e-09 6.11017768e-10 6.69091269e-09]\n",
      "Pred: [  8.00000046 419.99997397 309.99998084 999.99993661] Error: [2.10319692e-13 6.77371444e-10 3.66992546e-10 4.01872943e-09]\n",
      "Pred: [  8.00000036 419.99997983 309.99998515 999.99995087] Error: [1.26323266e-13 4.06846223e-10 2.20424900e-10 2.41374937e-09]\n",
      "Pred: [  8.00000028 419.99998437 309.99998849 999.99996192] Error: [7.58729113e-14 2.44362013e-10 1.32392705e-10 1.44975822e-09]\n",
      "Pred: [  8.00000021 419.99998789 309.99999108 999.99997049] Error: [4.55711674e-14 1.46769933e-10 7.95183684e-11 8.70761026e-10]\n",
      "Pred: [  8.00000017 419.99999061 309.99999309 999.99997713] Error: [2.73711822e-14 8.81536916e-11 4.77607199e-11 5.23000841e-10]\n",
      "Pred: [  8.00000013 419.99999272 309.99999464 999.99998228] Error: [1.64398167e-14 5.29473110e-11 2.86862827e-11 3.14127382e-10]\n",
      "Pred: [  8.0000001  419.99999436 309.99999585 999.99998626] Error: [9.87416465e-15 3.18014790e-11 1.72296985e-11 1.88672762e-10]\n",
      "Pred: [  8.00000008 419.99999563 309.99999678 999.99998935] Error: [5.93067036e-15 1.91007634e-11 1.03485878e-11 1.13321574e-10]\n",
      "Pred: [  8.00000006 419.99999661 309.99999751 999.99999175] Error: [3.56210882e-15 1.14723958e-11 6.21562044e-12 6.80637710e-11]\n",
      "Pred: [  8.00000005 419.99999738 309.99999807 999.99999361] Error: [2.13949165e-15 6.89060758e-12 3.73325716e-12 4.08808026e-11]\n",
      "Pred: [  8.00000004 419.99999797 309.9999985  999.99999504] Error: [1.28503212e-15 4.13867112e-12 2.24228756e-12 2.45540328e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [  8.00000003 419.99999842 309.99999884 999.99999616] Error: [7.71822389e-16 2.48578953e-12 1.34677398e-12 1.47477652e-11]\n",
      "Pred: [  8.00000002 419.99999878 309.9999991  999.99999702] Error: [4.63575819e-16 1.49302737e-12 8.08906032e-13 8.85787739e-12]\n",
      "Pred: [  8.00000002 419.99999905 309.9999993  999.99999769] Error: [2.78435227e-16 8.96749444e-13 4.85849201e-13 5.32026239e-12]\n",
      "Pred: [  8.00000001 419.99999927 309.99999946 999.99999821] Error: [1.67235117e-16 5.38610100e-13 2.91813160e-13 3.19548251e-12]\n",
      "Pred: [  8.00000001 419.99999943 309.99999958 999.99999861] Error: [1.00445596e-16 3.23502698e-13 1.75270265e-13 1.91928677e-12]\n",
      "Pred: [  8.00000001 419.99999956 309.99999968 999.99999893] Error: [6.03301443e-17 1.94303808e-13 1.05271721e-13 1.15277137e-12]\n",
      "Pred: [  8.00000001 419.99999966 309.99999975 999.99999917] Error: [3.62357865e-17 1.16703735e-13 6.32288125e-14 6.92383409e-13]\n",
      "Pred: [  8.         419.99999974 309.99999981 999.99999936] Error: [2.17641222e-17 7.00951734e-14 3.79768138e-14 4.15862668e-13]\n",
      "Pred: [  8.         419.99999979 309.99999985 999.9999995 ] Error: [1.30720772e-17 4.21009147e-14 2.28098230e-14 2.49777506e-13]\n",
      "Pred: [  8.         419.99999984 309.99999988 999.99999961] Error: [7.85141534e-18 2.52868465e-14 1.37001519e-14 1.50022617e-13]\n",
      "Pred: [  8.         419.99999988 309.99999991 999.9999997 ] Error: [4.71576078e-18 1.51879153e-14 8.22865271e-15 9.01073360e-14]\n",
      "Pred: [  8.         419.9999999  309.99999993 999.99999977] Error: [2.83240068e-18 9.12223948e-15 4.94233233e-15 5.41206777e-14]\n",
      "Pred: [  8.         419.99999993 309.99999995 999.99999982] Error: [1.70121413e-18 5.47903941e-15 2.96848975e-15 3.25062218e-14]\n",
      "Pred: [  8.         419.99999994 309.99999996 999.99999986] Error: [1.02178913e-18 3.29084919e-15 1.78294556e-15 1.95240574e-14]\n",
      "Pred: [  8.         419.99999996 309.99999997 999.99999989] Error: [6.13712795e-19 1.97656730e-15 1.07088363e-15 1.17266524e-14]\n",
      "Pred: [  8.         419.99999997 309.99999997 999.99999992] Error: [3.68611571e-19 1.18717535e-15 6.43199263e-16 7.04330817e-15]\n",
      "Pred: [  8.         419.99999997 309.99999998 999.99999993] Error: [2.21397074e-19 7.13046736e-16 3.86322563e-16 4.23039548e-15]\n",
      "Pred: [  8.         419.99999998 309.99999998 999.99999995] Error: [1.32976488e-19 4.28275284e-16 2.32034297e-16 2.54086953e-15]\n",
      "Pred: [  8.         419.99999998 309.99999999 999.99999996] Error: [7.98691286e-20 2.57231156e-16 1.39365063e-16 1.52610643e-15]\n",
      "Pred: [  8.         419.99999999 309.99999999 999.99999997] Error: [4.79710841e-20 1.54499428e-16 8.37063747e-17 9.16618881e-16]\n",
      "Pred: [  8.         419.99999999 309.99999999 999.99999998] Error: [2.88127983e-20 9.27963009e-17 5.02764839e-17 5.50545816e-16]\n",
      "Pred: [  8.         419.99999999 309.99999999 999.99999998] Error: [1.73058388e-20 5.57358419e-17 3.01968602e-17 3.30669617e-16]\n",
      "Pred: [  8.         419.99999999 310.         999.99999999] Error: [1.03942561e-20 3.34762249e-17 1.81370860e-17 1.98611563e-16]\n",
      "Pred: [  8.         420.         310.         999.99999999] Error: [6.24295180e-21 2.01065811e-17 1.08936717e-17 1.19292746e-16]\n",
      "Pred: [  8.         420.         310.         999.99999999] Error: [3.74967293e-21 1.20768709e-17 6.54312789e-18 7.16486660e-17]\n",
      "Pred: [  8.         420.         310.         999.99999999] Error: [2.25218102e-21 7.25354808e-18 3.92996619e-18 4.30330478e-17]\n",
      "Pred: [  8.         420.         310.         999.99999999] Error: [1.35272929e-21 4.35654367e-18 2.36041411e-18 2.58478225e-17]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [8.12445057e-22 2.61660767e-18 1.41762897e-18 1.55239525e-17]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [4.88002281e-22 1.57171756e-18 8.51447665e-19 9.32464678e-18]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.93112452e-22 9.43943825e-19 5.11435307e-19 5.60034693e-18]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.76029455e-22 5.66930580e-19 3.07163504e-19 3.36354157e-18]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.05746871e-22 3.40535899e-19 1.84477872e-19 2.02013020e-18]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [6.35007659e-23 2.04526662e-19 1.10805806e-19 1.21357865e-18]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.81478272e-23 1.22847811e-19 6.65410063e-20 7.28954207e-19]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.29010612e-23 7.37653950e-20 3.99900596e-20 4.37790509e-19]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.37569264e-23 4.43304702e-20 2.40111016e-20 2.63006225e-19]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [8.26071159e-24 2.66148593e-20 1.44264467e-20 1.57965854e-19]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [4.96198558e-24 1.59819566e-20 8.65880064e-21 9.49202678e-20]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.98121265e-24 9.61476293e-21 5.20335703e-21 5.69436433e-20]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.79392019e-24 5.76731003e-21 3.12224815e-21 3.42554103e-20]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.07618298e-24 3.46800642e-21 1.87616195e-21 2.05518322e-20]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [6.44669754e-25 2.07830421e-21 1.12858778e-21 1.23369982e-20]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.88753810e-25 1.25008963e-21 6.77784039e-22 7.40648473e-21]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.33452341e-25 7.50679331e-22 4.04917835e-22 4.45344995e-21]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.39155064e-25 4.51963732e-22 2.44357554e-22 2.68750981e-21]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [8.38369816e-26 2.69870906e-22 1.46595145e-22 1.61053358e-21]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [5.08941502e-26 1.62127400e-22 8.79687194e-23 9.70334557e-22]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.03048805e-26 9.78270321e-23 5.29395592e-23 5.80887585e-22]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.82258424e-26 5.80189652e-23 3.16687390e-23 3.51874878e-22]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.09840992e-26 3.49483809e-23 1.91576322e-23 2.11758237e-22]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [6.67691870e-27 2.11997344e-23 1.12477176e-23 1.26674956e-22]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.86541844e-27 1.28245307e-23 6.83716475e-24 7.66305289e-23]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.47386780e-27 7.75804942e-24 3.95818848e-24 4.65289095e-23]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.39155064e-27 4.66581564e-24 2.53324063e-24 2.61725116e-23]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [9.11923206e-28 2.71741756e-24 1.42494785e-24 1.58327539e-23]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [5.33269972e-28 1.56388835e-24 9.33809363e-25 1.01329625e-23]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-28 9.33809363e-25 5.46068451e-25 5.69979141e-24]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.01948392e-28 5.46068451e-25 3.23117427e-25 3.73523745e-24]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.13595970e-28 3.23117427e-25 2.06795153e-25 2.18427381e-24]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [5.04870979e-29 1.58327539e-25 1.16322274e-25 1.29246971e-24]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [5.04870979e-29 1.16322274e-25 5.16987883e-26 6.33310156e-25]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [2.83989926e-29 8.07793567e-26 5.16987883e-26 4.65289095e-25]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.26217745e-29 2.90805684e-26 2.90805684e-26 3.23117427e-25]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [1.26217745e-29 2.90805684e-26 1.29246971e-26 1.16322274e-25]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 1.29246971e-26 1.16322274e-25]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n",
      "Pred: [   8.  420.  310. 1000.] Error: [3.15544362e-30 1.29246971e-26 3.23117427e-27 5.16987883e-26]\n"
     ]
    }
   ],
   "source": [
    "input, goal_pred = np.array([2, 10, 11]), np.array([8, 420, 310, 1000]);\n",
    "weights = np.random.rand(3, 4);\n",
    "alpha = .001;\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    for i in range(iteration):\n",
    "        pred = input.dot(weights);\n",
    "        msquared_error = np.subtrac(pred, goal_pred) ** 2;\n",
    "        delta = np.subtract(pred, goal_pred);\n",
    "        output = [];\n",
    "        for i in range(len(delta)):\n",
    "            output.append((input * delta[i]));\n",
    "        weight_delta = np.array(output).T;\n",
    "        weights -= weight_delta * alpha;\n",
    "        print('Pred: ' + str(pred) + ' Error: ' + str(msquared_error));\n",
    "        #if(not np.any(msquared_error)): break;\n",
    "            \n",
    "neural_network(input, weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The takeaway:\n",
    "    Dot product is a loose measurement of similarity between \n",
    "    two vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the book will be spent exploring different types\n",
    "of weight combinations and error functions for which \n",
    "Gradient Descent is useful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
